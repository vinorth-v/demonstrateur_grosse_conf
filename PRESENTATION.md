# üé§ Guide de pr√©sentation pour la conf√©rence

## Timing: 15 minutes

### Slide 1: Titre (30 sec)
**"De 6 mois √† 2 jours : La r√©volution LLM pour le traitement documentaire"**

### Slide 2: Le probl√®me (2 min)
- Exemple concret: documents KYC bancaires
- Montrer les diff√©rents types de documents
- Complexit√©: formats vari√©s, cases √† cocher, validation m√©tier

**Point cl√©**: "Il y a 2 ans, ce projet aurait pris 6 mois et 100k‚Ç¨"

### Slide 3: L'approche classique (2 min)
D√©rouler le calvaire du deep learning classique:
- ‚ùå 10 000+ images annot√©es
- ‚ùå Bounding boxes pour chaque champ
- ‚ùå CNN pour classification
- ‚ùå D√©tection d'objets pour localisation
- ‚ùå Classificateur binaire pour cases coch√©es
- ‚ùå Post-processing OCR complexe
- ‚ùå Maintenance cauchemardesque

**Anecdote**: "Et si le format change? R√©-entra√Ænement complet!"

### Slide 4: L'approche LLM (1 min)
- ‚úÖ Quelques prompts bien r√©dig√©s
- ‚úÖ Sch√©mas Pydantic
- ‚úÖ R√®gles m√©tier en Python
- ‚úÖ C'est tout!

**Transition**: "Montrons-le en live..."

### D√âMO LIVE (8 min)

#### Partie 1: Classification (1 min)
```bash
python src/main.py examples/cni_exemple.jpg
```
- "Le LLM regarde le document"
- "Identifie instantan√©ment que c'est une CNI"
- Montrer la confiance √† 98%

#### Partie 2: Extraction structur√©e (2 min)
- Montrer le JSON retourn√©
- Souligner la structure Pydantic
- Validation automatique des dates

**Point technique**: "Avant, √ßa n√©cessitait du template matching ou de l'OCR + regex complexe"

#### Partie 3: ‚≠ê LE MOMENT FORT - Cases √† cocher (3 min)
```bash
python src/main.py examples/permis_exemple.jpg
```

**Setup dramatique**:
1. Afficher le permis de conduire
2. Zoomer sur la section des cat√©gories
3. "Regardez ces cases coch√©es. B et A2."

**Expliquer l'approche classique**:
- "Avant, il fallait:"
  - "1. Annoter des bounding boxes pour CHAQUE cat√©gorie"
  - "2. Entra√Æner un d√©tecteur pour localiser les cases"
  - "3. Entra√Æner un classificateur: coch√©e ou non?"
  - "4. G√©rer les cas ambigus: partiellement coch√©e, croix vs coche, etc."
  - "Des centaines d'heures de travail!"

**R√©v√©lation**:
- "Maintenant, regardez ce que je fais:"
- Afficher le prompt: *"Quelles cat√©gories sont coch√©es?"*
- Lancer l'extraction
- R√©sultat: `["B", "A2"]`
- **"C'EST TOUT!"**

**Silence dramatique de 2 secondes**

"Le LLM VOIT l'image. Il COMPREND que ce sont des cases. 
Il IDENTIFIE lesquelles sont coch√©es. Visuellement. 
Comme un humain."

**Impact**: "C'est √áA, la vraie r√©volution."

#### Partie 4: Dossier complet (2 min)
```bash
python src/main.py --folder examples/dossier_client_001/
```

- Pipeline automatique
- Validation de coh√©rence entre documents
- Rapport final: ACCEPT√â ou REJET√â

### Slide 5: Comparaison chiffr√©e (1 min)

| Crit√®re | Deep Learning | LLM |
|---------|--------------|-----|
| Temps dev | 3-6 mois | 2 jours |
| Co√ªt setup | 100k‚Ç¨ | ~0‚Ç¨ |
| Dataset | 10k images | 0 |
| Nouveaux formats | R√©-entra√Æner | Adapter prompt |

### Slide 6: Cas d'usage id√©aux (1 min)
O√π les LLM multimodaux excellent:
- ‚úÖ Documents √† mise en page variable
- ‚úÖ Formulaires avec cases √† cocher
- ‚úÖ Validation de coh√©rence contextuelle
- ‚úÖ Multi-format / multi-langue
- ‚úÖ Besoin de compr√©hension s√©mantique

### Slide 7: Limites actuelles (30 sec)
Honn√™tet√©:
- Co√ªt par document (vs one-time training)
- Latence ~2-3 secondes
- D√©pendance √† un provider

**Mais**: "Les mod√®les s'am√©liorent et se d√©mocratisent chaque mois"

### Slide 8: Conclusion (30 sec)
**Messages cl√©s:**
1. Paradigm shift: de "entra√Æner" √† "poser les bonnes questions"
2. D√©mocratisation de l'IA documentaire
3. Time-to-market r√©volutionnaire
4. On n'a pas encore vu le plein potentiel

**Phrase finale**: 
"Si vous avez un projet de traitement de documents, 
ne commencez pas par annoter des bounding boxes. 
Commencez par √©crire un prompt. 
Vous me remercierez dans 6 mois."

## üéØ Points d'attention

### Timing
- Garder 8 min pour la d√©mo live
- Ne pas s'attarder sur les slides
- Le public doit VOIR le code fonctionner

### Dramatisation
- Le moment "cases coch√©es" est LE climax
- Pr√©parer ce moment comme un magicien pr√©pare son tour
- Laisser le temps √† l'audience de comprendre l'ampleur de la simplification

### Backup plan
- Avoir des screenshots de la d√©mo au cas o√π
- Tester la connexion API avant
- Pr√©parer une vid√©o screencast en backup

### Questions attendues

**Q: "Mais le co√ªt API n'est-il pas prohibitif?"**
R: "Comparons: 0.03‚Ç¨/doc en API vs infrastructure GPU 24/7. 
Pour < 100k docs/mois, l'API est moins ch√®re."

**Q: "Et la confidentialit√© des donn√©es?"**
R: "Google Cloud permet du deployment on-premise avec Vertex AI. 
Ou utilisez un mod√®le open-source h√©berg√© localement."

**Q: "Quelle est la pr√©cision compar√©e?"**
R: "Dans nos tests: 92-97% pour LLM vs 85-92% pour notre ancien CNN. 
Et surtout: beaucoup moins de faux positifs."

**Q: "√áa marche avec quelle quantit√© de documents?"**
R: "Test√© avec succ√®s sur 500+ documents vari√©s. 
Zero-shot, sans fine-tuning."

## üìù Script mot-√†-mot (optionnel)

### Introduction
"Bonjour √† tous. Je vais vous montrer quelque chose qui m'a bluff√©.

Vous voyez ces documents? CNI, passeports, factures, RIB. 
Des trucs qu'on traite tous les jours dans les banques, assurances, administrations.

Il y a 2 ans, si on me demandait de cr√©er un syst√®me pour extraire automatiquement 
les donn√©es de ces documents, je vous aurais dit: 
'Ok, je reviens dans 6 mois avec une √©quipe de data scientists.'

Aujourd'hui, je peux faire la m√™me chose en 2 jours. Seul. 
Et avec de meilleurs r√©sultats.

Laissez-moi vous montrer comment..."

### Transition vers la d√©mo
"Assez parl√©. Voyons √ßa en action..."

### Moment cases coch√©es
"Et maintenant, le truc qui m'a fait dire 'wow'.

Regardez ce permis de conduire. Vous voyez ces petites cases? 
A, B, C, toutes ces cat√©gories?

En deep learning classique, d√©tecter quelles cases sont coch√©es, 
c'est un cauchemar. Des bounding boxes partout. 
Un mod√®le pour chaque case. Des faux positifs √† g√©rer.

Avec un LLM multimodal... regardez ma requ√™te: 
'Quelles cat√©gories sont coch√©es?'

[Lancer l'extraction]

Voil√†. B et A2. Correct.

C'est... magique? Non, c'est juste que le mod√®le VOIT l'image. 
Comme vous et moi. Il comprend visuellement.

√áa change TOUT."

### Conclusion
"Alors, pourquoi je vous montre √ßa?

Parce que si vous avez dans vos cartons un projet qui n√©cessite 
de traiter des documents, d'extraire des donn√©es, de comprendre 
des formulaires...

Ne partez pas bille en t√™te sur du deep learning classique.

Testez d'abord un LLM multimodal. Vous allez gagner 
des mois de d√©veloppement.

Et si √ßa fait le job? C'est tout b√©n√©f.

Merci!"

## üé¨ Checklist avant la conf

- [ ] Tester la d√©mo 3 fois le matin m√™me
- [ ] V√©rifier la connexion WiFi / 4G backup
- [ ] Credentials Google Cloud valides
- [ ] √âcran partag√© configur√©
- [ ] Terminal en police large et lisible
- [ ] Documents d'exemple bien pr√©par√©s
- [ ] Chronom√®tre pour le timing
- [ ] Bouteille d'eau √† port√©e
- [ ] Screencast backup au cas o√π
- [ ] Slides PDF en backup
- [ ] Contact pour questions apr√®s

Bon courage! üöÄ
